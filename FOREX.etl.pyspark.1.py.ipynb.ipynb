{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "!pip install ibmos2spark", 
            "cell_type": "code", 
            "execution_count": 1, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20190828175753-0000\nKERNEL_ID = 027b51da-7240-4a5f-a670-c35a048fb210\nCollecting ibmos2spark\n  Downloading https://files.pythonhosted.org/packages/c6/81/1edb24382edef1ca636e87972b2da286b8271a586c728a21f916d3cd76cd/ibmos2spark-1.0.1-py2.py3-none-any.whl\nInstalling collected packages: ibmos2spark\nSuccessfully installed ibmos2spark-1.0.1\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# Configuration\n# Each country has a tsv file with dates and exchange rates against\n# the U.S. dollar\n\nfiles = ['Australia.tsv', 'Brazil.tsv', 'Canada.tsv', 'China.tsv', \n         'Denmark.tsv', 'EU.tsv', 'Hong_Kong.tsv', 'India.tsv', \n         'Japan.tsv', 'Malaysia.tsv', 'New_Zealand.tsv', 'Norway.tsv',\n         'Singapore.tsv', 'South_Africa.tsv', 'South_Korea.tsv',\n         'Sri_Lanka.tsv', 'Sweden.tsv', 'Switzerland.tsv', 'Taiwan.tsv',\n         'Thailand.tsv', 'United_Kingdom.tsv','Venezuela.tsv']", 
            "cell_type": "code", 
            "execution_count": 2, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "import ibmos2spark\nfrom pyspark.sql.types import *\n\n# Configuration\n# Prepare to access IBM Object Storage\n\n# @hidden_cell\ncredentials = {\n    'service_id': 'iam-ServiceId-e4b1b62b-e030-4b68-a71f-a12e44f23c33',\n    'api_key': '9-RaWWhWwA-jm5BkfQ1pxtj-J5xvpjYKMrSgMk9vQxX1',\n    'endpoint': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n    'iam_service_endpoint': 'https://iam.ng.bluemix.net/oidc/token',\n    'bucket': 'forex-donotdelete-pr-ksiby6mz5os7oj'\n}\n\n# configuration_name = 'os_forex'\nconfiguration_name = ''\ncos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n\nprint(type(cos))\n\nbucket_name = 'forex-donotdelete-pr-ksiby6mz5os7oj'", 
            "cell_type": "code", 
            "execution_count": 3, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "<class 'ibmos2spark.osconfig.CloudObjectStorage'>\n"
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "# 'Date' formats come in as a string separated by '-' with:\n#  1 or 2 day-digits\n#  three letter month categoricals\n#  2 digit year-digits\n\ndef reformatMonth(a):\n    month_dict = {'Jan':'01',\n              'Feb':'02',\n              'Mar':'03',\n              'Apr':'04',\n              'May':'05',\n              'Jun':'06',\n              'Jul':'07',\n              'Aug':'08',\n              'Sep':'09',\n              'Oct':'10',\n              'Nov':'11',\n              'Dec':'12'\n             }\n    try: \n        x = re.search(r\"([0-9]+-)(.*)(-[0-9][0-9])\", a)\n        if len(x.groups()[0])==3:\n            return ''.join([x.groups()[0], month_dict[x.groups()[1]], x.groups()[2]])\n        else:\n            return ''.join(['0',x.groups()[0], month_dict[x.groups()[1]], x.groups()[2]])\n    except:\n        return None", 
            "cell_type": "code", 
            "execution_count": 4, 
            "outputs": [], 
            "metadata": {}
        }, 
        {
            "source": "import re\nfrom datetime import datetime \nfrom pyspark.sql.types import StructType, StructField, StringType, FloatType, DateType\n\n# Loop through all tsv files \n# Remove rows with incomplete data, such as 'ND'\n# Reformat 'Date' fields\n# Set correct data types for all fields \n\nschema = StructType([StructField(\"Date\", DateType(), True),\n                     StructField(\"Rate\", FloatType(), True)\n                    ])\n\ndf_all = None\ncountries = []\n\nfor object_name in files:\n    data_url = cos.url(object_name, bucket_name)\n    df = spark.read.format(\"csv\").option(\"header\", True).option(\"delimiter\", \"\\t\").option(\"nullValue\",'ND').load(data_url) #.schema(forexSchema)\n    df2 = df.where(df.Rate.isNotNull())\n    print(object_name + \" contains \" + str(df2.count()) + \" rows\")\n    tmp = re.search(r\"(.*)\\.tsv\", object_name)\n    country_name = tmp.groups()[0]\n    countries.append(country_name)\n    rdd = df2.rdd.map(lambda r: (datetime.strptime(reformatMonth(r[0]), '%d-%m-%y'),float(r[1])))\n    df_new = sqlContext.createDataFrame(rdd, schema)\n    df_new = df_new.withColumnRenamed('Date', 'Date2')\n    df_new = df_new.withColumnRenamed('Rate', country_name)\n\n\n    if df_all == None:\n        df_all = df_new.withColumnRenamed('Date2', 'Date')\n        print(\"Creating dataframe for country \" + country_name)\n    else:\n        # df_all = df_all.union(df_new)\n        df_all = df_all.join(df_new, df_all.Date == df_new.Date2)\n        df_all = df_all.drop('Date2')\n        print(\"Joining to dataframe for country \" + country_name)\ndf_all = df_all.sort('Date', ascending=True)\ndf_all.take(5)", 
            "cell_type": "code", 
            "execution_count": 5, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Australia.tsv contains 4926 rows\nCreating dataframe for country Australia\nBrazil.tsv contains 4927 rows\nJoining to dataframe for country Brazil\nCanada.tsv contains 4927 rows\nJoining to dataframe for country Canada\nChina.tsv contains 4923 rows\nJoining to dataframe for country China\nDenmark.tsv contains 4927 rows\nJoining to dataframe for country Denmark\nEU.tsv contains 4927 rows\nJoining to dataframe for country EU\nHong_Kong.tsv contains 4927 rows\nJoining to dataframe for country Hong_Kong\nIndia.tsv contains 4926 rows\nJoining to dataframe for country India\nJapan.tsv contains 4927 rows\nJoining to dataframe for country Japan\nMalaysia.tsv contains 4927 rows\nJoining to dataframe for country Malaysia\nNew_Zealand.tsv contains 4927 rows\nJoining to dataframe for country New_Zealand\nNorway.tsv contains 4927 rows\nJoining to dataframe for country Norway\nSingapore.tsv contains 4927 rows\nJoining to dataframe for country Singapore\nSouth_Africa.tsv contains 4926 rows\nJoining to dataframe for country South_Africa\nSouth_Korea.tsv contains 4927 rows\nJoining to dataframe for country South_Korea\nSri_Lanka.tsv contains 4927 rows\nJoining to dataframe for country Sri_Lanka\nSweden.tsv contains 4927 rows\nJoining to dataframe for country Sweden\nSwitzerland.tsv contains 4927 rows\nJoining to dataframe for country Switzerland\nTaiwan.tsv contains 4924 rows\nJoining to dataframe for country Taiwan\nThailand.tsv contains 4927 rows\nJoining to dataframe for country Thailand\nUnited_Kingdom.tsv contains 4926 rows\nJoining to dataframe for country United_Kingdom\nVenezuela.tsv contains 4920 rows\nJoining to dataframe for country Venezuela\n"
                }, 
                {
                    "output_type": "execute_result", 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[Row(Date=datetime.date(2000, 1, 4), Australia=0.6561999917030334, Brazil=1.840499997138977, Canada=1.451799988746643, China=8.279899597167969, Denmark=7.2179999351501465, EU=1.030900001525879, Hong_Kong=7.777500152587891, India=43.54999923706055, Japan=103.08999633789062, Malaysia=3.799999952316284, New_Zealand=0.5198000073432922, Norway=7.934000015258789, Singapore=1.653499960899353, South_Africa=6.085000038146973, South_Korea=1122.5, Sri_Lanka=72.6500015258789, Sweden=8.359999656677246, Switzerland=1.55649995803833, Taiwan=30.600000381469727, Thailand=37.130001068115234, United_Kingdom=1.6369999647140503, Venezuela=0.6503000259399414),\n Row(Date=datetime.date(2000, 1, 5), Australia=0.6549999713897705, Brazil=1.8559999465942383, Canada=1.451799988746643, China=8.279800415039062, Denmark=7.208000183105469, EU=1.0334999561309814, Hong_Kong=7.7779998779296875, India=43.54999923706055, Japan=103.7699966430664, Malaysia=3.799999952316284, New_Zealand=0.5170999765396118, Norway=7.934999942779541, Singapore=1.656000018119812, South_Africa=6.070000171661377, South_Korea=1135.0, Sri_Lanka=72.94999694824219, Sweden=8.352999687194824, Switzerland=1.5526000261306763, Taiwan=30.799999237060547, Thailand=37.099998474121094, United_Kingdom=1.6414999961853027, Venezuela=0.6514999866485596),\n Row(Date=datetime.date(2000, 1, 6), Australia=0.6539999842643738, Brazil=1.840000033378601, Canada=1.4571000337600708, China=8.27970027923584, Denmark=7.212500095367432, EU=1.0324000120162964, Hong_Kong=7.778500080108643, India=43.54999923706055, Japan=105.19000244140625, Malaysia=3.799999952316284, New_Zealand=0.5145000219345093, Norway=7.940000057220459, Singapore=1.6655000448226929, South_Africa=6.079999923706055, South_Korea=1146.5, Sri_Lanka=72.94999694824219, Sweden=8.367500305175781, Switzerland=1.5540000200271606, Taiwan=31.75, Thailand=37.619998931884766, United_Kingdom=1.6475000381469727, Venezuela=0.6503000259399414),\n Row(Date=datetime.date(2000, 1, 7), Australia=0.6547999978065491, Brazil=1.8309999704360962, Canada=1.4505000114440918, China=8.279399871826172, Denmark=7.228499889373779, EU=1.0293999910354614, Hong_Kong=7.778299808502197, India=43.54999923706055, Japan=105.16999816894531, Malaysia=3.799999952316284, New_Zealand=0.515999972820282, Norway=7.966000080108643, Singapore=1.662500023841858, South_Africa=6.057000160217285, South_Korea=1138.0, Sri_Lanka=73.1500015258789, Sweden=8.414999961853027, Switzerland=1.5622999668121338, Taiwan=30.850000381469727, Thailand=37.29999923706055, United_Kingdom=1.6383999586105347, Venezuela=0.6507999897003174),\n Row(Date=datetime.date(2000, 1, 10), Australia=0.6560999751091003, Brazil=1.819000005722046, Canada=1.4567999839782715, China=8.279399871826172, Denmark=7.254000186920166, EU=1.0252000093460083, Hong_Kong=7.778500080108643, India=43.54999923706055, Japan=105.27999877929688, Malaysia=3.799999952316284, New_Zealand=0.5167999863624573, Norway=8.02400016784668, Singapore=1.6618000268936157, South_Africa=6.076499938964844, South_Korea=1133.5, Sri_Lanka=73.30000305175781, Sweden=8.449000358581543, Switzerland=1.5703999996185303, Taiwan=30.829999923706055, Thailand=37.27000045776367, United_Kingdom=1.6374000310897827, Venezuela=0.6517999768257141)]"
                    }, 
                    "execution_count": 5
                }
            ], 
            "metadata": {}
        }, 
        {
            "source": "data_url = cos.url(\"etl.parquet\", bucket_name)\ndf_all.write.parquet(data_url)\n", 
            "cell_type": "code", 
            "execution_count": 9, 
            "outputs": [], 
            "metadata": {}
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark", 
            "name": "python36", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }
}